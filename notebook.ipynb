{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3rc1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ff1ade0fc2833020167c1da0ab0f0d067ae8c8f8d100dbb8b3e17b047ea7a012"
   }
  },
  "interpreter": {
   "hash": "ff1ade0fc2833020167c1da0ab0f0d067ae8c8f8d100dbb8b3e17b047ea7a012"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tesseract"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "img = cv.imread('test-300.png',0)\n",
    "equ = cv.equalizeHist(img)\n",
    "cv.imwrite('res.png',equ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def remove_noise_and_smooth(file_name='0_flipped.jpg'):\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 41,3)\n",
    "    cv2.imwrite('mask.png',filtered)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imwrite('closing.png',closing)\n",
    "    img = image_smoothening(img,90)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image\n",
    "\n",
    "def image_smoothening(img, threshold):\n",
    "    ret1, th1 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imwrite('th1.png',th1)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    cv2.imwrite('th2.png',th2)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    cv2.imwrite('blur.png',blur)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    cv2.imwrite('th3.png',th3)\n",
    "    return th3\n",
    "\n",
    "cv2.imwrite('prova.png',remove_noise_and_smooth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n",
    "    \n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            highlight = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            highlight = 255 + brightness\n",
    "        alpha_b = (highlight - shadow)/255\n",
    "        gamma_b = shadow\n",
    "        \n",
    "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
    "    else:\n",
    "        buf = input_img.copy()\n",
    "    \n",
    "    if contrast != 0:\n",
    "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
    "        alpha_c = f\n",
    "        gamma_c = 127*(1-f)\n",
    "        \n",
    "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
    "\n",
    "    return buf\n",
    "\n",
    "def incicciottisci(img, kernelsize=3, shape=cv2.MORPH_ELLIPSE):\n",
    "    kernel = cv2.getStructuringElement(shape,(kernelsize,kernelsize))\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    dilation = cv2.dilate(opening,kernel,iterations = 2)\n",
    "    return (255-dilation)\n",
    "\n",
    "img = cv2.imread('0_flipped.jpg', 0)\n",
    "bc=apply_brightness_contrast(img,103,43)\n",
    "filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 41,3)\n",
    "cv2.imwrite('mask.jpg',filtered)\n",
    "blur_otsu = cv2.GaussianBlur(bc,(7,7),0)\n",
    "_,thr = cv2.threshold(blur_otsu,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "or_image = cv2.bitwise_or(thr, filtered)\n",
    "#cic=incicciottisci(255-or_image, 3)\n",
    "#blur= cv2.blur(cic,(3,3))\n",
    "cv2.imwrite('prova1.png',thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tesseract result (LCDDot_FT_500.traineddata):\n B7 #;#  #;# P #;#  #;# 5 #;#  #;# L2AK77 #;# 11-2022 #;# \f\nTesseract result (dotslayer.traineddata):\n S7 #;#  #;# Y: #;#  #;# 5 #;# W #;#  #;# LL2OF77 #;# 11LP2QO22 #;# \f\nTesseract result (ita.traineddata):\n P #;#  #;#  . #;#  #;# - #;# .. #;#  #;# LECGKF7 #;# 11-2022 #;# \f\nTesseract result (eng.traineddata):\n T #;#  #;# P #;#  #;# - #;#  #;# LEK77 #;# 11-2022 #;# \f\n"
     ]
    }
   ],
   "source": [
    "#py -m pip install pytesseract\n",
    "#py -m pip install --upgrade pip\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "image='Img2_flipped.jpg'\n",
    "#print('OSD: ',pytesseract.image_to_osd(image,lang='LCDDot_FT_500',config='-c min_characters_to_try=5')) # meh non funziona...\n",
    "LCDDot_FT_500=pytesseract.image_to_string(image, lang='LCDDot_FT_500', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGJKLMNOPQRSTUVWXYZ.-:\").replace('\\n',' #;# ')\n",
    "dotslayer=pytesseract.image_to_string(image, lang='dotslayer', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGJKLMNOPQRSTUVWXYZ.-:\").replace('\\n',' #;# ')\n",
    "ita=pytesseract.image_to_string(image, lang='ita', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGJKLMNOPQRSTUVWXYZ.-:\").replace('\\n',' #;# ')\n",
    "eng=pytesseract.image_to_string(image, lang='eng', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGJKLMNOPQRSTUVWXYZ.-:\").replace('\\n',' #;# ')\n",
    "print(\"Tesseract result (LCDDot_FT_500.traineddata):\\n\",LCDDot_FT_500)\n",
    "print(\"Tesseract result (dotslayer.traineddata):\\n\",dotslayer)\n",
    "print(\"Tesseract result (ita.traineddata):\\n\",ita)\n",
    "print(\"Tesseract result (eng.traineddata):\\n\",eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Immagini labellate con il testo che dovremmo riconoscere (basta fare una ricerca sul se la stringa trovata con tesseract e' contenuta nella stringa di ogni chiave del dizionario dell immagini)\n",
    "# Provare poi sostituendo i caratteri ambigui come \"O\" e \"0\"; penso siano gli unici in quanto sostiuire i le \"T\" con i \"7\" non sarebbe corretto o i \"5\" con le \"S\" (e viceversa tutti i casi)\n",
    "labels={'Img0': ['LOTTO:L20L0M\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img1': ['LOTTO:L20L0M\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img2': ['L20K77\\n11-2022\\n'],\n",
    "\t\t\t\t'Img3': ['L20K77\\n11-2022\\n'],\n",
    "\t\t\t\t'Img4': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img5': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img6': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img7': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img8': ['L20L09\\n12-2022\\n'],\n",
    "\t\t\t\t'Img9': ['L20L09\\n12-2022\\n'],\n",
    "        'Img10': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img11': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img12': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img13': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img14': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img15': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img16': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img17': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img18': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img19': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img20': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img21': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img22': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img23': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img24': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img25': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img26': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img27': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img28': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img29': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img30': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img31': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img32': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img33': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img34': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img35': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img36': [''],\n",
    "\t\t\t\t'Img37': [''],\n",
    "\t\t\t\t'Img38': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img39': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img40': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img40_lowExp': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img41': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img42': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img42_lowExp': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img43': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img44': ['LOTTO:L20K6X\\nSCAD.:11-2023\\n'],\n",
    "\t\t\t\t'Img45': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img46': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img47': [''],\n",
    "\t\t\t\t'Img48': [''],\n",
    "\t\t\t\t'Img49': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img50': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img51': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "\t\t\t\t'Img52': ['LOTTO:L20L0L\\nSCAD.:12-2022\\n'],\n",
    "        }\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "from os.path import exists, join, isfile, isdir\n",
    "from os import listdir\n",
    "import json\n",
    "\n",
    "detected_folder='./metodo_2'\n",
    "folders=[d for d in listdir(detected_folder) if isdir(join(detected_folder,d))]\n",
    "json_dict={}\n",
    "#with open('results.txt', 'w') as the_file:\n",
    "for folder in ['buoni_refiner_3_4x4','scarti_refiner_3_4x4']:\n",
    "\timages=[d for d in listdir(join(detected_folder,folder)) if isdir(join(detected_folder,folder,d))]\n",
    "\timages.sort()\n",
    "\tfor image in images:\n",
    "\t\tfiles=[f for f in listdir(join(detected_folder,folder,image)) if isfile(join(detected_folder,folder,image,f))]\n",
    "\t\tLCDDot_FT_500=[]\n",
    "\t\tdotslayer=[]\n",
    "\t\tita=[]\n",
    "\t\teng=[]\n",
    "\t\tfor file in files:\n",
    "\t\t\t# In caso si utilizzi il metodo 2: psm=8 per indicare a tesseract che dovra' rilevare una singola parola, oem=3 di default e nessuna whitelist per ora\n",
    "\t\t\t# Senza usare il file trainato per il font a matrice di punti\n",
    "\t\t\t# Ha bisogno dell'utilizzo della funzione link dots per ingrassare i punti e cercare di rendere il font normale\n",
    "\t\t\timg=join(detected_folder,folder,image,file)\n",
    "\t\t\t# Suppongo si possano togliere caratteri tipo la O o lo 0, la I o L'1, la A con il 4, Z con 2\n",
    "\t\t\t# (per evitare casi ambigui suppongo si possano stampare solo determinate combinazioni con meno caratteri, come nelle targhe... Poi si puo' modificare in ogni caso)\n",
    "\t\t\tLCDDot_FT_500.append(pytesseract.image_to_string(img, lang='LCDDot_FT_500', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPRSTUVWXY.-:\").replace('\\x0c','').replace(' ',''))\n",
    "\t\t\tdotslayer.append(pytesseract.image_to_string(img, lang='dotslayer', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPRSTUVWXY.-:\").replace('\\x0c','').replace(' ',''))\n",
    "\t\t\tita.append(pytesseract.image_to_string(img, lang='ita', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPRSTUVWXY.-:\").replace('\\x0c','').replace(' ',''))\n",
    "\t\t\teng.append(pytesseract.image_to_string(img, lang='eng', config=\"-c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPRSTUVWXY.-:\").replace('\\x0c','').replace(' ',''))\n",
    "\t\tjson_dict[image]={\"written\":labels[image],\"found\":{\"LCDDot_FT_500\":LCDDot_FT_500,\"dotslayer\":dotslayer,\"ita\":ita,\"eng\":eng}}\n",
    "\t\t\t#the_file.write(image+'({})\\n'.format(labels[image]))\n",
    "            #the_file.write(\"\\tTesseract result (LCDDot_FT_500.traineddata): {}\\n\".format(LCDDot_FT_500))\n",
    "            #the_file.write(\"\\tTesseract result (dotslayer.traineddata): {}\\n\".format(dotslayer))\n",
    "            #the_file.write(\"\\tTesseract result (ita.traineddata): {}\\n\".format(ita))\n",
    "            #the_file.write(\"\\tTesseract result (eng.traineddata): {}\\n\".format(eng))\n",
    "y = json.dumps(json_dict)\n",
    "with open('results_4x4.txt', 'w') as the_file:\n",
    "\tthe_file.write(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "def create_mask(image):\n",
    "    gray=cv2.imread(image,0)\n",
    "    #gray = cv2.cvtColor( image, cv2.COLOR_BGR2GRAY )\n",
    "    blurred = cv2.GaussianBlur( gray, (9,9), 0 )\n",
    "    _,thresh_img = cv2.threshold( blurred, 240, 255, cv2.THRESH_BINARY)\n",
    "    thresh_img = cv2.erode( thresh_img, None, iterations=2 )\n",
    "    thresh_img  = cv2.dilate( thresh_img, None, iterations=4 )\n",
    "    # perform a connected component analysis on the thresholded image,\n",
    "    # then initialize a mask to store only the \"large\" components\n",
    "    labels = measure.label( thresh_img, background=0 )\n",
    "    mask = np.zeros( thresh_img.shape, dtype=\"uint8\" )\n",
    "    # loop over the unique components\n",
    "    for label in np.unique( labels ):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels\n",
    "        labelMask = np.zeros( thresh_img.shape, dtype=\"uint8\" )\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero( labelMask )\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > 300:\n",
    "            mask = cv2.add( mask, labelMask )\n",
    "    return mask\n",
    "image='0_flipped.jpg'\n",
    "img=cv2.imread(image,0)\n",
    "mask=create_mask(image)\n",
    "cv2.imwrite('new.jpg',cv2.inpaint(img , mask, 10, cv2.INPAINT_NS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "image='2_flipped.jpg'\n",
    "gray=cv2.imread(image,0)\n",
    "im_pil = Image.fromarray(gray)\n",
    "#img = Image.open(filename)\n",
    "im_pil.save('prova.jpg', dpi=(300.0, 300.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}