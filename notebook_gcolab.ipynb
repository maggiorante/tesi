{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "random.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QmC7kUlDc3wT",
        "eN-h-h7-etg1",
        "iBIefF2usTmm",
        "FWG93fHsgIGS",
        "H26Utm_hdI1Q",
        "Y0b6F_qghvZy",
        "O2xvaaJ_eBCC",
        "S3RVHkHaU25y",
        "KpM9lWrWGUa-",
        "Xui3gPuhGHjI",
        "4L2ZxgmxGfPi",
        "c8hk8JrU5v-_",
        "drY5HXd_50nw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmC7kUlDc3wT"
      },
      "source": [
        "# Generale\n",
        "\n",
        "<b>ELABORATO SCRITTO</b>: Salva le varie prove di preprocessing e poi dividi i vari formati nelle immagini di test trovati e come reagiscono a diversi valori di soglia, luminosita' e contrasto per fare un confronto. Commenta l'utilizzo delle due tecniche dopo la detection e delle varie configurazioni possibili per il detector, quale sia meglio usare e quale no. In generale confronta tutti procedimenti fatti, nulla e' stato inventato o fatto da zero ma sono state fatte varie prove. Fai le varie prove con vari preprocessing e poi esegui tutta la pipeline per ogni cartella preprocessata per vedere come finisce tutto e poi confronta\n",
        "\n",
        "<b>Controllato e i file trainati di tesseract funzionano se non si prova su google colab quindi la parte di riconoscimento con quelli la faccio dopo sul computer confrontando tutti e 3 i modelli (ita, dot1 e dot2)</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN-h-h7-etg1"
      },
      "source": [
        "## Installazione tesseract, altro necessario e mount di GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mNqXGoxz72o",
        "outputId": "a7530e25-e382-4e57-8d05-be84d36d5ad5"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install tesseract-ocr-ita\n",
        "!pip install pytesseract\n",
        "!sudo apt install git\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 2s (2,833 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-ita\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,062 kB of archives.\n",
            "After this operation, 2,717 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-ita all 4.00~git24-0e00fe6-1.2 [1,062 kB]\n",
            "Fetched 1,062 kB in 1s (878 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-ita.\n",
            "(Reading database ... 160819 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-ita_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-ita (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-ita (4.00~git24-0e00fe6-1.2) ...\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13953 sha256=616cc09eee997a5154a7126543c4897b22b2662eae95e734d4830d35a2fde167\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.7\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBIefF2usTmm"
      },
      "source": [
        "## Conversione immagini da bmp a jpg\n",
        "(CRAFT, ad esempio, non accetta bmp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxnwsOJsGui"
      },
      "source": [
        "import cv2\n",
        "from os import listdir, mkdir\n",
        "from os.path import isfile, join, isdir, exists\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        #out = np.zeros_like(img)\n",
        "        # White-padding\n",
        "        out=np.full_like(img,255)\n",
        "\n",
        "        #out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
        "        out[top:top+zh, left:left+zw]=cv2.resize(img, None, fx=zoom_factor, fy=zoom_factor)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out\n",
        "\n",
        "rootFolder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto'\n",
        "dirs=['buoni','scarti']\n",
        "for dir in dirs:\n",
        "  if (not exists(join(rootFolder,dir+\"_jpg\"))):\n",
        "    mkdir(join(rootFolder,dir+\"_jpg\"))\n",
        "  files=[f for f in listdir(join(rootFolder,dir)) if isfile(join(rootFolder,dir,f))]\n",
        "  for file in files:\n",
        "    img=cv2.imread(join(rootFolder,dir,file))\n",
        "    new=clipped_zoom(img,0.9)\n",
        "    #new=cv.resize(zoomed, (1280, 1280))\n",
        "    cv2.imwrite(join(rootFolder,dir+\"_jpg\",file.split('.')[0]+\".jpg\"),new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWG93fHsgIGS"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "Basta trovare una soglia che in generale possa far risaltare il testo per la fase di detection. Dopo la fase di detection il riquadro viene ritagliato dall'immagine originale e poi si riapplica un processing piu' leggero visto che a quel punto le zone individuate dovrebbero contenere solo testo su uno sfondo che possiamo eliminare facilmente con qualche soglia magari. Piu' aggressivo ora per eliminare eventuali problemi e rendere molto affidabile la fase di detection, poi qualcosa di meno distruttivo verso i contorni delle lettere magari per utilizzare al meglio tesseract\n",
        "<br/><br/>\n",
        "\n",
        "<b>DONE/TODO</b>: Prova ad aumentare il contrasto a 30 e anche la luminosita' (valore di GIMP)<br/>\n",
        "<b>IDEA</b>: Implementazione ad-hoc di un algoritmo per la soglia dipendentemente dall'immagine finale che si avra' dall'azienda che si occupa della fase di acquisizione\n",
        "<br/><br/>\n",
        "<b>Giocare un po' con i valori di luminosita', contrasto e threshold per trovare un buon compromesso per la detection. Non sembra possibili agire solo su luminosita' e contrasto per avere meno errori possibili durante la fase di detection ma bisogna passare al thresholding. (E' anche vero che non abbiamo ancora immagini aggiornate quindi in futuro potrebbe migliorare il tutto) Se ci fossero troppi errori sarebbe da implementare la parte di codice che rileva il punto a concentrazione maggiore di bounding box se si utilizzasse il metodo 1</b>\n",
        "\n",
        "<b>DONE/TODO</b>: Problemi con l'immagine 2 e 3, provare ad applicare una \"ricostruzione\" allargando i punti che a volte sono troppo lontani! Usata una soglia diversa per queste due immagini, quando in produzione avremo un formato standard dell'immagine acuquisita avremo una soglia unica ma per ora usiamo qualcosa ad hoc per queste 2 che altrimenti non funzionano\n",
        "\n",
        "<b>Non funziona il resize della funzione ma non sembra creare problemi. Nei consigli su come usare tesseract e preparare le immagini pero' consigliano una risoluzione di 300DPI che ora non riesco a fare. Controllando i risultati vedo se sistemare</b>\n",
        "\n",
        "Scoperto che CRAFT funziona molto bene se si inverte l'immagine, il testo diventa bianco e quindi sembra ci siano meno anomalie rilevate come testo!\n",
        "\n",
        "Notare che per il pre processing delle immagini nel formato 1, 2 e 4 basta una soglia accuratamente scelta (meglio comunque metter mano anche a contrasto e luminosita' per evitare di prendere troppo poco)\n",
        "\n",
        "<b>\n",
        "IMAGE_SIZE = 1280\n",
        "-----IDEA: Implementazione ad-hoc di un algoritmo per la soglia dipendentemente dall'immagine finale che si avra' dall'azienda che si occupa della fase di acquisizione\n",
        "BINARY_THREHOLD = 50\n",
        "-----Heavy pre-process se usiamo le non invertite, si potrebbe sperimentare ancora con i valori ma fino a che non si ha un formato standard non troveremo mai molto...per adesso se ne usa solo uno visto che poi avremo un solo tipo di immagini\n",
        "BRIGHTNESS=-20 # preproc=-20/inverted=[20 35 40]\n",
        "CONTRAST=30 # preproc=30/inverted=[45 25 40]\n",
        "</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRusPOOygKtv"
      },
      "source": [
        "import tempfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from os import listdir, mkdir\n",
        "from os.path import isfile, join, exists\n",
        "\n",
        "\n",
        "# Da questo post di stackoverflow: https://stackoverflow.com/questions/39308030/how-do-i-increase-the-contrast-of-an-image-in-python-opencv\n",
        "def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n",
        "    \n",
        "    if brightness != 0:\n",
        "        if brightness > 0:\n",
        "            shadow = brightness\n",
        "            highlight = 255\n",
        "        else:\n",
        "            shadow = 0\n",
        "            highlight = 255 + brightness\n",
        "        alpha_b = (highlight - shadow)/255\n",
        "        gamma_b = shadow\n",
        "        \n",
        "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
        "    else:\n",
        "        buf = input_img.copy()\n",
        "    \n",
        "    if contrast != 0:\n",
        "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
        "        alpha_c = f\n",
        "        gamma_c = 127*(1-f)\n",
        "        \n",
        "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
        "\n",
        "    return buf\n",
        "\n",
        "# Da questo post di stackoverflow: https://stackoverflow.com/questions/28935983/preprocessing-image-for-tesseract-ocr-with-opencv\n",
        "\n",
        "def process_image_for_ocr(file_path, brightness, contrast, threshold, img_size=1280):\n",
        "    # TODO : Implement using opencv\n",
        "    temp_filename = set_image_dpi(file_path, img_size)\n",
        "    im_new = remove_noise_and_smooth(temp_filename, brightness, contrast, threshold)\n",
        "    return im_new\n",
        "\n",
        "def set_image_dpi(file_path, img_size):\n",
        "    im = Image.open(file_path)\n",
        "    length_x, width_y = im.size\n",
        "    factor = max(1, int(img_size / length_x))\n",
        "    size = factor * length_x, factor * width_y\n",
        "    # size = (1800, 1800)\n",
        "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
        "    temp_filename = temp_file.name\n",
        "    im_resized.save(temp_filename, dpi=(300, 300))\n",
        "    return temp_filename\n",
        "\n",
        "def image_smoothening(img, brightness, contrast, threshold):\n",
        "    img=apply_brightness_contrast(img,brightness,contrast)\n",
        "    ret1, th1 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
        "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
        "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return th3\n",
        "\n",
        "def remove_noise_and_smooth(file_name, brightness, contrast, threshold):\n",
        "    img = cv2.imread(file_name, 0)\n",
        "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 41,3)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "    img = image_smoothening(img, brightness, contrast, threshold)\n",
        "    or_image = cv2.bitwise_or(img, closing)\n",
        "    return or_image\n",
        "\n",
        "# Funzione per incicciottire il font e renderlo \"continuo\" da puntinato\n",
        "# Vuole in input l'immagine in bianco su nero e non nero su bianco\n",
        "# Restituisce poi un'immagine in bianco e nero\n",
        "\n",
        "def incicciottisci(img, kernelsize=3, shape=cv2.MORPH_ELLIPSE):\n",
        "    kernel = cv2.getStructuringElement(shape,(kernelsize,kernelsize))\n",
        "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "    dilation = cv2.dilate(opening,kernel,iterations = 2)\n",
        "    return (255-dilation)\n",
        "\n",
        "images_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto'\n",
        "preproc_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/preprocessing'\n",
        "dirs=['buoni_jpg','scarti_jpg']\n",
        "method=3\n",
        "if (not exists(preproc_folder)):\n",
        "    mkdir(preproc_folder)\n",
        "#formato124={\"buoni_jpg\":[\"Img0.jpg\",\"Img1.jpg\",\"Img2.jpg\",\"Img3.jpg\",\"Img8.jpg\",\"Img9.jpg\"]}\n",
        "#formato3={\"buoni_jpg\":[\"Img4.jpg\",\"Img5.jpg\",\"Img6.jpg\",\"Img7.jpg\"]}\n",
        "for dir in dirs:\n",
        "    saveto=join(preproc_folder,dir+'_preproc_'+\"{}\".format(method))\n",
        "    if (not exists(saveto)):\n",
        "        mkdir(saveto)\n",
        "    files=[f for f in listdir(join(images_folder,dir)) if isfile(join(images_folder,dir,f))]\n",
        "    for file in files:\n",
        "        if method==0:\n",
        "            img=cv2.imread(join(images_folder,dir,file), 0)\n",
        "            final=apply_brightness_contrast(img,40,40)\n",
        "        elif method==1:\n",
        "            # Pre processing con la funzione trovata online\n",
        "            final=process_image_for_ocr(join(images_folder,dir,file),-20,30,50)\n",
        "            final=incicciottisci(255-final)\n",
        "        elif method==2:\n",
        "            img=cv2.imread(join(images_folder,dir,file), 0)\n",
        "            bc=apply_brightness_contrast((255-img),40,40)\n",
        "            blur = cv2.blur(bc,(3,3))\n",
        "            _, thr = cv2.threshold(blur, 250, 255, cv2.THRESH_BINARY_INV)\n",
        "            # 3 o 5 come kernel size\n",
        "            final=incicciottisci(255-thr)\n",
        "        elif method==3:\n",
        "            # Tarato sull'immagine circa peggiore trovata, la 27 degli scarti, da tarare poi in base al formato finale delle immagini catturate\n",
        "            img=cv2.imread(join(images_folder,dir,file), 0)\n",
        "            bc=apply_brightness_contrast(img,50,50)\n",
        "            blur= cv2.blur(bc,(5,5))\n",
        "            final=incicciottisci(255-blur,5)\n",
        "        cv2.imwrite(join(saveto,file),final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ-QhK_scyF3"
      },
      "source": [
        "# CRAFT-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H26Utm_hdI1Q"
      },
      "source": [
        "## Clonazione della repository, download dei modelli e installazione dei moduli richiesti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECqRcUo9tAzL",
        "outputId": "da4cbfb5-35df-44c1-9457-99dcb0eaecf1"
      },
      "source": [
        "from os.path import join, exists\n",
        "from os import mkdir\n",
        "#destination_folder='/content/drive/MyDrive/tesi/CRAFT-pytorch'\n",
        "destination_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/CRAFT-pytorch'\n",
        "if not exists(destination_folder):\n",
        "  !git clone https://github.com/clovaai/CRAFT-pytorch '$destination_folder'\n",
        "if not exists(join(destination_folder,'weights')):\n",
        "  mkdir(join(destination_folder,'weights'))\n",
        "if not exists(join(destination_folder,'weights','craft_mlt_25k.pth')):\n",
        "  filename=join(destination_folder,'weights','craft_mlt_25k.pth')\n",
        "  !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ' -O '$filename'\n",
        "if not exists(join(destination_folder,'weights','craft_refiner_CTW1500.pth')):\n",
        "  filename=join(destination_folder,'weights','craft_refiner_CTW1500.pth')\n",
        "  !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XSaFwBkOaFOdtk4Ane3DFyJGPRw6v5bO' -O '$filename'\n",
        "!pip install torch torchvision opencv-python scikit-image scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 07:57:07--  https://docs.google.com/uc?export=download&id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.33.206, 2607:f8b0:4004:82a::200e\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.33.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nkur1pa91c776gqli9bc0eoba26t6495/1624262175000/05173585031594261940/*/1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-06-21 07:57:09--  https://doc-0k-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nkur1pa91c776gqli9bc0eoba26t6495/1624262175000/05173585031594261940/*/1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ?e=download\n",
            "Resolving doc-0k-9g-docs.googleusercontent.com (doc-0k-9g-docs.googleusercontent.com)... 172.217.2.97, 2607:f8b0:4004:80a::2001\n",
            "Connecting to doc-0k-9g-docs.googleusercontent.com (doc-0k-9g-docs.googleusercontent.com)|172.217.2.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘/content/drive/Shareddrives/Tesi Martignetti-Papallazi/CRAFT-pytorch/weights/craft_mlt_25k.pth’\n",
            "\n",
            "/content/drive/Shar     [      <=>           ]  79.30M  67.4MB/s    in 1.2s    \n",
            "\n",
            "2021-06-21 07:57:11 (67.4 MB/s) - ‘/content/drive/Shareddrives/Tesi Martignetti-Papallazi/CRAFT-pytorch/weights/craft_mlt_25k.pth’ saved [83152330]\n",
            "\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0b6F_qghvZy"
      },
      "source": [
        "## Esecuzione\n",
        "Opzioni di configurazione per CRAFT:\n",
        "<ul>\n",
        "  <li><b>--trained_model</b>: pretrained model (default: weights/craft_mlt_25k.pth)</li>\n",
        "  <li><b>--text_threshold</b>: certainty required for something to be classified as a letter. The higher this value the clearer characters need to look. (recommended 0.5-0.6) (default: 0.7)</li>\n",
        "  <li><b>--low_text</b>: amount of boundary space around the letter-word when the coordinates are returned. The higher this value the less space. Upping this value also affects the link threshold of seeing words as one, but it can cut off unnecessary borders around letters. Having this value too high can affect edges of letters, cutting them off and lowering the accuracy in reading them. (recommended 0.3-0.4) (default: 0.4)</li>\n",
        "  <li><b>--link_threshold</b>: amount of distance allowed between two characters for them to be seen as a single word. (recommended 0.1-0.5, however playing with this value for your own use case might be better) (default: 0.4)</li>\n",
        "  <li><b>--cuda</b>: use cuda for inference (default: True)</li>\n",
        "  <li><b>--canvas_size</b>: image size for inference (images are resized to this size) (default: 1280)</li>\n",
        "  <li><b>--mag_ratio</b>: image magnification ratio (default: 1.5)</li>\n",
        "  <li><b>--poly</b>: enable polygon type (default: False)</li>\n",
        "  <li><b>--show_time</b>: show processing time (default: False)</li>\n",
        "  <li><b>--test_folder</b>: folder path containing the images (default: /data/)</li>\n",
        "  <li><b>--refine</b>: enable link refiner (default: False)</li>\n",
        "  <li><b>--refine_model</b>: pretrained refiner model (default: weights/craft_refiner_CTW1500.pth)</li>\n",
        "</ul>\n",
        "\n",
        "<br/>\n",
        "<b>Notiamo che passando l'immagine preprocessata in bianco e nero ci mette davvero poco a rilevare il tutto, il che potrebbe permetterci di puntare piu' sulla parte di preprocessing anche se prendesse un po' piu' tempo</b> (interessante scrivere il confronto di tempi sull'elaborato di tesi magari))\n",
        "<br/><br/>\n",
        "<b>Tratta il caso sia con che senza il Refiner, usandolo sarebbe meglio ricorrere al metodo 1 (da rivedere ora che nel preprocessing uso anche la funzione per incicciottire i punti). Usando il refiner sembra sia molto meglio il risultato ma alcune bounding box sono sovrapposte e dovrebbe essere fatto il merge in una unica per evitare di riconoscere 2 volte la stessa parole o riconoscerne un pezzo e non essere sicuri poi del risultato...</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uWWIXcOyzkv",
        "outputId": "a1333f32-1cda-4f47-b2d1-f72b94efbdce"
      },
      "source": [
        "#CRAFT_folder='/content/drive/MyDrive/tesi/CRAFT-pytorch'\n",
        "CRAFT_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/CRAFT-pytorch'\n",
        "%cd '$CRAFT_folder'\n",
        "from os import rename\n",
        "from os.path import join, exists\n",
        "from os import mkdir\n",
        "test_path=join(CRAFT_folder,'test.py')\n",
        "results_path=join(CRAFT_folder,'result')\n",
        "new_results_path=['buoni_results_refiner_{}','buoni_results_{}','scarti_results_refiner_{}','scarti_results_{}']\n",
        "preproc_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/preprocessing'\n",
        "method=3\n",
        "buoni_dir=join(preproc_folder,\"buoni_jpg_preproc_{}\".format(method))\n",
        "scarti_dir=join(preproc_folder,\"scarti_jpg_preproc_{}\".format(method))\n",
        "detect=False\n",
        "if detect:\n",
        "  !python '$test_path' --test_folder='$buoni_dir'\n",
        "  rename(results_path, join(CRAFT_folder,new_results_path[1].format(method)))\n",
        "  !python '$test_path' --test_folder='$buoni_dir' --refine\n",
        "  rename(results_path, join(CRAFT_folder,new_results_path[0].format(method)))\n",
        "  !python '$test_path' --test_folder='$scarti_dir'\n",
        "  rename(results_path, join(CRAFT_folder,new_results_path[3].format(method)))\n",
        "  !python '$test_path' --test_folder='$scarti_dir' --refine\n",
        "  rename(results_path, join(CRAFT_folder,new_results_path[2].format(method)))\n",
        "    \n",
        "\n",
        "toshared=False\n",
        "results_copy_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/CRAFT_results'\n",
        "if (not exists(results_copy_folder)):\n",
        "    mkdir(results_copy_folder)\n",
        "\n",
        "if toshared:\n",
        "  for path in new_results_path:\n",
        "    path=path.format(method)\n",
        "    temp=join(CRAFT_folder,path)\n",
        "    !cp -R '$path' '$results_copy_folder'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tesi/CRAFT-pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2xvaaJ_eBCC"
      },
      "source": [
        "## Metodo 1 (ABBANDONATO E NON AGGIORNATO, I PERCORSI NON SONO CORRETTI...)\n",
        "\n",
        "Singolo rettangolo che contiene tutto il testo delle bounding box ma richiede che il nostro pre-processing porti alla detection del solo testo corretto e all'eliminazione di qualsiasi altra anomalia\n",
        "\n",
        "Si potrebbe cercare di prendere solo le aree \"dense di bounding boxes\" e non considerare le altre\n",
        "\n",
        "Lo skew viene calcolato facendo una media dell'angolo di ogni bounding box quindi risulta facile ad errori se una bounding box viene trovata un po' a caso (in alcuni casi viene trovata una bounding box che contiene le sole coppie di \":\" e non sempre ha un'angolazione corretta, portanto ad errore nella media poi)\n",
        "\n",
        "Aggiustamento possibilie: Controlla prima se esiste una zona con una concentrazione di punti maggiore altrimenti usa il metodo 2 poi, magari ha un suo senso come soluzione\n",
        "\n",
        "Il metodo 1 ha sicuramente molti problemi negli scarti dove le bounding box potrebbero essere molte e neanche vicine causando inutilita' nelle considerazioni fatte...probabilmente e' meglio il metodo 2 che analizza ogni singola boundibg box\n",
        "\n",
        "Il modo migliore sarebbe: cercare l'area con una concentrazione di punti maggiore cosi' da elimintare possibili outliers (dato che siamo abbastanza certi di trovare una zona con molte bounding box, almeno 4, e altre sparse in giro se il preprocessing viene fatto bene), utilizzare un qualche metodo per trovare il rettangolo piu' grande che possa contenere tutte le bounding box e poi leggere una singola bounding box. Per ora prendo solo la x minore, maggiore e la y minore e maggiore per poi creare un riquadro con queste dimensioni. Questo caso potrebbe non funzionare nel momento in cui le immagini con anomalie deformano il testo e quindi leggere le singole bounding box risulta meglio che crearne una sola, inoltre il processo potrebbe essere davvero troppo oneroso e la possibilita' di errori (vista la mancanza di immagini con un formato standard in questo momento) viene ad essere alta. Propenderei per il metodo 2 che semplifica il tutto..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3RVHkHaU25y"
      },
      "source": [
        "### Pre-processing Tesseract NEW\n",
        "\n",
        "<b>Metodo che funziona solo se viene implementata la funzione che trova il punto a maggiore concentrazione di rettangoli. Vedendo l'analisi degli scarti notiamo come i problemi di illuminazione portano al rilevamento di molte bounding box presumibilmente contententi testo e questo andrebbe a rendere totalmente inutile anche questa modifica in questa fase. Inoltre l'algoritmo per la zona maggiormente densa di bounding box, che si riduce ad un calcolo del centro della regione piu' densa di punti, dovrebbe lavorare dinamicamente e valutare anche il caso in cui ci sia il rettangolo piu' grande ma sempre guardando i casi di scarto questo metodo non e' infallibile. Se in futuro potesse migliorare l'illuminazione, potendo in questo modo tarare un pre processing piu' fine, potremmo ricorrere a questa tecnica che sicuramente ci aiuta molto. Utilizzando questa potremmo anche usare tesseract per verifica se il testo e' capovolto oppure no, cosa che adesso non possiamo fare dato che avendo troppi pochi caratteri tesseract ci restituisce errore... Riportiamo il primo metodo solo per i casi buoni, nel caso degli scarti produce troppi errori, basta guardare ai casi delle immagini con tanti riquadri trovati. Si potrebbe pensare ad una soluzione che in base al numero di rettangolo rilevati utilizzi il metodo 1 (in caso di massimo 10 rettangoli trovati, accenttando ci siano degli outliers, valutando anche il caso di rettangolo piu' grande di altri) e metodo 2 in caso ci siano troppi rettangoli per evitare di commettere errori e analizzare ogni singola area di testo potenzialmente rilevata</b>\n",
        "\n",
        "image_to_osd di pytesseract ha bisogno di almeno 50 caratteri, potremmo provare a giocare con min_characters_to_try ma non dovrebbe comunque bastare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "RhF8c8R5VMf6",
        "outputId": "aac1a7b0-58dc-421f-86df-692082ce4f98"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "from os import mkdir, listdir\n",
        "from os.path import isfile, join, exists\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.spatial import ConvexHull\n",
        "from scipy.spatial import distance as dist\n",
        "\n",
        "def order_points(pts):\n",
        "\t# sort the points based on their x-coordinates\n",
        "\txSorted = pts[np.argsort(pts[:, 0]), :]\n",
        "\t# grab the left-most and right-most points from the sorted\n",
        "\t# x-roodinate points\n",
        "\tleftMost = xSorted[:2, :]\n",
        "\trightMost = xSorted[2:, :]\n",
        "\t# now, sort the left-most coordinates according to their\n",
        "\t# y-coordinates so we can grab the top-left and bottom-left\n",
        "\t# points, respectively\n",
        "\tleftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
        "\t(tl, bl) = leftMost\n",
        "\t# now that we have the top-left coordinate, use it as an\n",
        "\t# anchor to calculate the Euclidean distance between the\n",
        "\t# top-left and right-most points; by the Pythagorean\n",
        "\t# theorem, the point with the largest distance will be\n",
        "\t# our bottom-right point\n",
        "\tD = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
        "\t(br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
        "\t# return the coordinates in top-left, top-right,\n",
        "\t# bottom-right, and bottom-left order\n",
        "\treturn np.array([tl, tr, br, bl], dtype=\"int32\")\n",
        "\n",
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        #out = np.zeros_like(img)\n",
        "        # White-padding\n",
        "        out=np.full_like(img,255)\n",
        "\n",
        "        #out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
        "        out[top:top+zh, left:left+zw]=cv2.resize(img, None, fx=zoom_factor, fy=zoom_factor)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out\n",
        "\n",
        "def rotate_image(image, angle, center):\n",
        "  # Questa volta ruoto secondo il punto contro cui calcolo lo skew\n",
        "  image_center = tuple(np.array(center))\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], borderValue=(255,255,255))\n",
        "  return result\n",
        "\n",
        "def minimum_bounding_rectangle(points):\n",
        "    \"\"\"\n",
        "    Find the smallest bounding rectangle for a set of points.\n",
        "    Returns a set of points representing the corners of the bounding box.\n",
        "\n",
        "    :param points: an nx2 matrix of coordinates\n",
        "    :rval: an nx2 matrix of coordinates\n",
        "    \"\"\"\n",
        "    from scipy.ndimage.interpolation import rotate\n",
        "    pi2 = np.pi/2.\n",
        "\n",
        "    # get the convex hull for the points\n",
        "    hull_points = points[ConvexHull(points).vertices]\n",
        "\n",
        "    # calculate edge angles\n",
        "    edges = np.zeros((len(hull_points)-1, 2))\n",
        "    edges = hull_points[1:] - hull_points[:-1]\n",
        "\n",
        "    angles = np.zeros((len(edges)))\n",
        "    angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
        "\n",
        "    angles = np.abs(np.mod(angles, pi2))\n",
        "    angles = np.unique(angles)\n",
        "\n",
        "    # find rotation matrices\n",
        "    # XXX both work\n",
        "    rotations = np.vstack([\n",
        "        np.cos(angles),\n",
        "        np.cos(angles-pi2),\n",
        "        np.cos(angles+pi2),\n",
        "        np.cos(angles)]).T\n",
        "#     rotations = np.vstack([\n",
        "#         np.cos(angles),\n",
        "#         -np.sin(angles),\n",
        "#         np.sin(angles),\n",
        "#         np.cos(angles)]).T\n",
        "    rotations = rotations.reshape((-1, 2, 2))\n",
        "\n",
        "    # apply rotations to the hull\n",
        "    rot_points = np.dot(rotations, hull_points.T)\n",
        "\n",
        "    # find the bounding points\n",
        "    min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
        "    max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
        "    min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
        "    max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
        "\n",
        "    # find the box with the best area\n",
        "    areas = (max_x - min_x) * (max_y - min_y)\n",
        "    best_idx = np.argmin(areas)\n",
        "\n",
        "    # return the best box\n",
        "    x1 = max_x[best_idx]\n",
        "    x2 = min_x[best_idx]\n",
        "    y1 = max_y[best_idx]\n",
        "    y2 = min_y[best_idx]\n",
        "    r = rotations[best_idx]\n",
        "\n",
        "    rval = np.zeros((4, 2))\n",
        "    rval[0] = np.dot([x1, y2], r)\n",
        "    rval[1] = np.dot([x2, y2], r)\n",
        "    rval[2] = np.dot([x2, y1], r)\n",
        "    rval[3] = np.dot([x1, y1], r)\n",
        "\n",
        "    return rval\n",
        "\n",
        "work_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_1'\n",
        "images_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto'\n",
        "CRAFT_folder='/content/drive/MyDrive/tesi/CRAFT-pytorch'\n",
        "\n",
        "if not exists(work_folder):\n",
        "  mkdir(work_folder)\n",
        "if not exists(join(work_folder,'buoni')):\n",
        "  mkdir(join(work_folder,'buoni'))\n",
        "if not exists(join(work_folder,'scarti')):\n",
        "  mkdir(join(work_folder,'scarti'))\n",
        "for folder in ['buoni_results_refiner_preproc']: #['buoni_results','scarti_results']:\n",
        "  files=[f.split('.')[0] for f in listdir(join(CRAFT_folder,folder)) if isfile(join(CRAFT_folder,folder,f)) and (f.split('.')[1]=='txt')]\n",
        "  for file in files:\n",
        "    with open(join(CRAFT_folder,folder,file+'.txt')) as fin:\n",
        "      points=[]\n",
        "      x=[]\n",
        "      y=[]\n",
        "      for line in fin:\n",
        "          if len(line)!=1:\n",
        "            coord=line.rstrip().split(',')\n",
        "            for i in range(0,len(coord),2):\n",
        "              points.append([int(coord[i]),int(coord[i+1])])\n",
        "    if points!=None:\n",
        "      pts=np.array(minimum_bounding_rectangle(np.array(points)),np.int32)\n",
        "      pts=order_points(pts)\n",
        "      # Calcolo l'angolazione della bounding box negandola in segno per poi sistemare lo skew (potrebbe non essere il metodo migliore se il detector sbaglia con la bounding box)\n",
        "      diffs=[pts[0,0]-pts[3,0],pts[0,1]-pts[3,1]]\n",
        "      angle=-(math.atan(diffs[0]/diffs[1])*180/math.pi)\n",
        "      # Calcolo la lunghezza dei lati del rettangolo della bounding box\n",
        "      dist1=math.ceil(sqrt((pts[3,0]-pts[0,0])**2+(pts[3,1]-pts[0,1])**2))\n",
        "      dist2=math.ceil(sqrt((pts[1,0]-pts[0,0])**2+(pts[1,1]-pts[0,1])**2))\n",
        "      # Ruoto l'immagine rispetto al punto rispetto a cui ho calcolato l'angolo\n",
        "      im=cv2.imread(join(images_folder,folder.split('_')[0]+'_jpg_preproc',file.split('_')[1]+'.jpg'),0)\n",
        "      final=rotate_image(im,angle,[pts[0,0],pts[0,1]])\n",
        "      # Ritaglio la zona di interesse\n",
        "      final=final[pts[0,1]:pts[0,1]+dist1,pts[0,0]:pts[0,0]+dist2]\n",
        "      # Se in verticale la giro\n",
        "      if final.shape[0]>final.shape[1]:\n",
        "        final=cv2.rotate(final,0)\n",
        "      # TODO: Applica il pre-processing prima di fare lo zoom per portare tutto in bianco e nero (dovrebbe essere piu' semplice la questione relativa alle soglie a questo punto)\n",
        "      \n",
        "      #final=remove_noise_and_smooth(final)\n",
        "      #print(final[::].max())\n",
        "      # Faccio uno zoom di 0.5 per \"aggiungere area\"\n",
        "      final=clipped_zoom(final,0.5)\n",
        "      final_flipped=cv2.rotate(final,1)\n",
        "      # Salvo\n",
        "      cv2.imwrite(join(work_folder,folder.split('_')[0],file.split('_')[1]+'.jpg'),final)\n",
        "      cv2.imwrite(join(work_folder,folder.split('_')[0],file.split('_')[1]+'_flipped.jpg'),final_flipped)\n",
        "    else:\n",
        "      print(\"Non e' stata rilevata la presenza di alcun testo (nessuna boundig box) nell'immagine \"+join(images_folder,folder.split('_')[0]+'_jpg',file.split('_')[1]+'.jpg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-68eefb6704dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;31m# Ruoto l'immagine rispetto al punto rispetto a cui ho calcolato l'angolo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_jpg_preproc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m       \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m       \u001b[0;31m# Ritaglio la zona di interesse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdist1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdist2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-68eefb6704dd>\u001b[0m in \u001b[0;36mrotate_image\u001b[0;34m(image, angle, center)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mimage_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0mrot_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRotationMatrix2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_center\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborderValue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpM9lWrWGUa-"
      },
      "source": [
        "### Pre-processing Tesseract OLD <b>(NON USARE)</b>\n",
        "<b>DONE/TODO</b>: Ritaglia dall'immagine originale e non pre-processata e poi riesegui il preprocessing<br/>\n",
        "<b>DONE/TODO</b>: Sistema in caso non ci siano bounding box rilevate...<br/>\n",
        "<b>TODO</b>: In base alla grandezza del rettangolo trovato che contiene tutto prova a fare uno zoom variabile (?)<br/>\n",
        "<b>TODO</b>: Cerca i rettangoli piu' vicini prima di raddrizzare, in questo modo elimini i casi strani oppure lavora sul preprocessing (utilizzalo in congiunzione al metodo sopra per riunire tutto per bene)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzb9GkqSb8FN"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from os import listdir, mkdir\n",
        "from os.path import isfile, join, exists\n",
        "import math\n",
        "from statistics import mean\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        #out = np.zeros_like(img)\n",
        "        out=np.full_like(img,255)\n",
        "\n",
        "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "  # Ruotiamo l'immagine rispetto al centro dell'immagine stessa. Il ritaglio poi dovrebbe starci tutto anche nel rettangolo singolo che andiamo a calcolare\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv.INTER_LINEAR,borderValue=(255,255,255))\n",
        "  return result\n",
        "\n",
        "def skew_angle(filename):\n",
        "  # Calcola l'angolo medio di sfasamento fra tutte le bounding box rilevate\n",
        "  with open(filename) as fin:\n",
        "    angle=[]\n",
        "    for line in fin:\n",
        "      if len(line)!=1:\n",
        "        coord=line.rstrip().split(',')\n",
        "        diffs=[int(coord[0])-int(coord[-2]),int(coord[1])-int(coord[-1])]\n",
        "        angle.append(-(math.atan(diffs[0]/diffs[1])*180/math.pi))\n",
        "  return mean(angle)\n",
        "\t\t\t  \n",
        "\n",
        "def single_bounding_box(filename):\n",
        "  # Difficilmente potremo trovare una singola bounding box e anche se la trovassimo perderemmo l'informazione sull'angolazione del testo, dovendo quindi raddrizzare in un altro modo\n",
        "  # Questo sembra un metodo abbastanza funzionante (genero i punti usando le x e le y minori e maggiori), sicuramente porta a livelli di zoom diversi e quindi dovremo valutare in fase di testing cosa comporta\n",
        "  with open(filename) as fin:\n",
        "    x=[]\n",
        "    y=[]\n",
        "    rot=[]\n",
        "    for line in fin:\n",
        "        if len(line)!=1:\n",
        "          coord=line.rstrip().split(',')\n",
        "          x.append(coord[0::2])\n",
        "          y.append(coord[1::2])\n",
        "    flat_list_x = [int(item) for sublist in x for item in sublist]\n",
        "    flat_list_y = [int(item) for sublist in y for item in sublist]\n",
        "  return [[min(flat_list_x),min(flat_list_y)],[max(flat_list_x),min(flat_list_y)],[max(flat_list_x),max(flat_list_y)],[min(flat_list_x),max(flat_list_y)]]\n",
        "\n",
        "def link_dots(img):\n",
        "    #kernel=cv.getStructuringElement(cv.MORPH_ELLIPSE,(3,3))\n",
        "    #kernel=cv.getStructuringElement(cv.MORPH_CROSS,(3,3))\n",
        "    #kernel=cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
        "    matrix=[[3,5,3],[5,9,5],[3,5,3]]\n",
        "    kernel=np.array(matrix,np.uint8)\n",
        "    opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n",
        "    dilation = cv.dilate(opening,kernel,iterations = 2)\n",
        "    return (255-dilation)\n",
        "\n",
        "\n",
        "# TODO: Ritaglia dall'immagine originale e non pre-processata e poi riesegui il preprocessing \n",
        "# DONE/TODO: Sistema in caso non ci siano bounding box rilevate...\n",
        "# TODO: In base alla grandezza del rettangolo trovato che contiene tutto prova a fare uno zoom variabile (?)\n",
        "# TODO: Cerca i rettangoli piu' vicini prima di raddrizzare, in questo modo elimini i casi strani oppure lavora sul preprocessing\n",
        "\n",
        "# Notare che il caso dell'immagine 7 non funziona bene visto che la soglia scelta nel pre-processing porta a rilevare anche altro e ad una bounding box sbagliata di conseguenza... Sistemare quello o\n",
        "# guardare questo link https://stackoverflow.com/questions/57539749/find-out-centre-of-the-most-dense-region-in-a-scatter-plot per trovare il punto piu' denso di punti nella nostra immagine, ovvero\n",
        "# in cui si concentrano piu' bounding box ed eliminare le altre, quelle lontane dal punto \"caldo\", che saranno presumibilmente errori\n",
        "\n",
        "work_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_1'\n",
        "images_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto'\n",
        "CRAFT_folder='/content/drive/MyDrive/tesi/CRAFT-pytorch'\n",
        "\n",
        "if not exists(work_folder):\n",
        "  mkdir(work_folder)\n",
        "if not exists(join(work_folder,'buoni')):\n",
        "  mkdir(join(work_folder,'buoni'))\n",
        "if not exists(join(work_folder,'scarti')):\n",
        "  mkdir(join(work_folder,'scarti'))\n",
        "for folder in ['buoni_results']: #['buoni_results','scarti_results']:\n",
        "  files=[f.split('.')[0] for f in listdir(join(CRAFT_folder,folder)) if isfile(join(CRAFT_folder,folder,f)) and (f.split('.')[1]=='txt')]\n",
        "  for file in files:\n",
        "    filename=join(CRAFT_folder,folder,file+'.txt')\n",
        "    box=single_bounding_box(filename)\n",
        "    angle=skew_angle(filename)\n",
        "    if box!=None and angle!=None:\n",
        "      im=cv.imread(join(images_folder,folder.split('_')[0]+'_jpg',file.split('_')[1]+'.jpg'))\n",
        "      # Possibile problema in caso non ci stia la rotazione...guardare https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/ in caso\n",
        "      final=rotate_image(im[box[0][1]:box[2][1], box[0][0]:box[1][0]],angle)\n",
        "      # TODO: Applica il pre-processing prima di fare lo zoom per portare tutto in bianco e nero (dovrebbe essere piu' semplice la questione relativa alle soglie a questo punto)\n",
        "      # TODO: Ingrassare i puntini o usare file di tesseract trainato su font a matrice di punti\n",
        "      #final=clipped_zoom(link_dots(255-final),0.5)\n",
        "      final=clipped_zoom(final,0.5)\n",
        "      if final.shape[0]>final.shape[1]:\n",
        "        final=cv.rotate(final,0)\n",
        "      final_flipped=cv.rotate(final,1)\n",
        "      cv.imwrite(join(work_folder,folder.split('_')[0],file.split('_')[1]+'.jpg'),final)\n",
        "      cv.imwrite(join(work_folder,folder.split('_')[0],file.split('_')[1]+'_flipped.jpg'),final_flipped)\n",
        "    else:\n",
        "      print(\"Non e' stata rilevata la presenza di alcun testo (nessuna boundig box) nell'immagine \"+join(images_folder,folder.split('_')[0]+'_jpg',file.split('_')[1]+'.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xui3gPuhGHjI"
      },
      "source": [
        "### Riconoscimento\n",
        "Provare ad utilizzare il modello trainato di tesseract per i display a matrice di punti trovato su github per vedere se performa meglio dell'iniciccionimento dei punti per cercare di far diventare il font puntinato continuo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPwFbCKVG5j3"
      },
      "source": [
        "import pytesseract\n",
        "from os.path import exists, join, isfile\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "\n",
        "traineddata_folder='/content/drive/MyDrive/tesi'\n",
        "tessdata_folder='/usr/share/tesseract-ocr/4.00/tessdata'\n",
        "if not exists(join(traineddata_folder,'LCDDot_FT_500.traineddata')):\n",
        "  !wget https://github.com/ameera3/OCR_Expiration_Date/blob/master/OCR_Ensemble/LCDDot_FT_500.traineddata\n",
        "if not exists(join(traineddata_folder,'dotslayer.traineddata')):\n",
        "  !wget https://github.com/Shreeshrii/tessdata_shreetest/blob/master/dotslayer.traineddata\n",
        "\n",
        "copyfile(join(traineddata_folder,'LCDDot_FT_500.traineddata'), join(tessdata_folder,'LCDDot_FT_500.traineddata'))\n",
        "copyfile(join(traineddata_folder,'dotslayer.traineddata'), join(tessdata_folder,'dotslayer.traineddata'))\n",
        "#from os import listdir, chdir, mkdir\n",
        "#from os.path import isfile, join, isdir, exists\n",
        "#import cv2 as cv\n",
        "#root_folder_images='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/cut'\n",
        "#files=[f for f in listdir(root_folder_images) if isfile(join(root_folder_images,f)) and (f.split('.')[1]=='jpg')]\n",
        "#for file in files:\n",
        "#  print(join(root_folder_images,file))\n",
        "#  print(pytesseract.image_to_string(join(root_folder_images,file)))\n",
        "#  print('\\n')\n",
        "\n",
        "# Sintassi generale per usare il comando con le opzioni di configurazione per tesseract\n",
        "#target = pytesseract.image_to_string(image, lang='eng', boxes=False, config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
        "# Da prelevare l'immagine giusta o la cartella con le immagini di tutte le boundibg box ritagliate\n",
        "detected_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_1'\n",
        "first_method_ita=[]\n",
        "first_method_LCDDot=[]\n",
        "first_method_dotslayer=[]\n",
        "for folder in ['buoni']:\n",
        "  images=[f for f in listdir(join(detected_folder,folder)) if isfile(join(detected_folder,folder,f))]\n",
        "  images.sort()\n",
        "  for image in images:\n",
        "    img=join(detected_folder,folder,image)\n",
        "    print(img)\n",
        "    #print(pytesseract.image_to_string(img,config='--psm 0 -c min_characters_to_try=5'))\n",
        "    # In caso si utilizzi il metodo 1: nessuna configurazione particolare e andiamo alla buona per riconoscere le 2 righe\n",
        "    # (notiamoche di default tesseract si aspetta un blocco lungo di testo e magari crea errore)\n",
        "    first_method_ita.append(pytesseract.image_to_string(img, lang='ita'))\n",
        "    print(first_method_ita[-1])\n",
        "    #first_method_LCDDot.append(pytesseract.image_to_string(img, lang='LCDDot_FT_500'))\n",
        "    #first_method_dotslayer.append(pytesseract.image_to_string(img, lang='dotslayer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5bGjnjvT214"
      },
      "source": [
        "## Metodo 2 (UNICO DA USARE CONTINUATO AD ESSERE AGGIORNATO, L'ALTRO POTREBBE NON ESSERE COMPATIBILE CON I CAMBI DI CARTELLE ORA)\n",
        "\n",
        "Ritaglio ogni bounding box, creo una cartella che le contiene tutte e poi le analizzo una ad una. A noi interessa solo trovare una data che ha sempre un dash (\"-\") che la contraddistingue e un numero di lotto che invece non contiene quel carattere. Delle parole \"Lotto\", \"Scad.\" e dei due punti ci interessa relativamente a questo punto ma non abbiamo la \"visione d'insieme\" richiesta da Leandro con un singolo riquadro che contiene tutto\n",
        "\n",
        "Possibile integrare il metodo uno e il metodo 2 per analizzare con il metodo 2 e salvare un risultato con il metodo 1 per scopi di storico magari\n",
        "\n",
        "Utilizza il secondo link di github trovato e prova se sia meglio riconoscere una sola parola. Per impostare tesseract a riconoscere una sola parola -psm=8 (mi sembra) o guarda sulla pagina del tutorial di tesseract. Imposta i caratteri che potrebbero comparire ed elimina tutti gli altri possibilie (sempre dalle opzioni di tesseract)\n",
        "\n",
        "Troppi poche lettere per fari si' che tesseract ci possa rilevare se il testo e' sottosopra... L'unica idea possibile e' cercare la parola lotto (quando il formato della scritta lo contiene) e utilizzare il set di immagini (flipped o no) in base a che tipo di immagine questa fosse. Nelle immagini in cui la scritta lotto non compare ha senso salvare entrambe le copie del valore a meno che non contengano valori strani...\n",
        "\n",
        "Non si riescono ad utilizzare i traineddata per display a matrice di punti per non si sa quale motivo, scaricando e installando la lingua italiana per tesseract i risultati migliorano abbastanza\n",
        "\n",
        "<b>Si potrebbe mettere un limite minimo alla grandezza della bounding box, scartando quelle troppo piccole. Non credo si possa fare lo stesso ragionamento al contrario</b>\n",
        "\n",
        "Le ultime immagini degli scarti, secondo me, sarebbero facilmente riconoscibili se non si usasse la funzione incicciottisci o con un kernel piu' piccolo. Un kernel piu' piccolo rovinerebbe gli altri casi senza un modello trainato... una volta che si avra' un modello trainato non avremo piu' bisogno neanche della funzione incicciottisti!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6quuUQhGchl"
      },
      "source": [
        "### Pre-processing Tesseract\n",
        "<b>DONE/TODO</b>: Applica il pre-processing prima di fare lo zoom per portare tutto in bianco e nero (dovrebbe essere piu' semplice la questione relativa alle soglie a questo punto)\n",
        "\n",
        "<b>TODO</b>: Provare diversi valori di soglia per il pre-processing (conviene abbassarla)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_T58jkfVvdd",
        "outputId": "f15a93f2-6aab-454d-8cac-b5d8537da8f4"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "from os import mkdir, listdir\n",
        "from os.path import isfile, join, exists\n",
        "from scipy.ndimage import zoom\n",
        "from scipy.spatial import ConvexHull\n",
        "from scipy.spatial import distance as dist\n",
        "from PIL import Image\n",
        "\n",
        "# Ordina i punti derivati dal calcolo del MRB: https://www.pyimagesearch.com/2016/03/21/ordering-coordinates-clockwise-with-python-and-opencv/\n",
        "\n",
        "def order_points(pts):\n",
        "\t# sort the points based on their x-coordinates\n",
        "\txSorted = pts[np.argsort(pts[:, 0]), :]\n",
        "\t# grab the left-most and right-most points from the sorted\n",
        "\t# x-roodinate points\n",
        "\tleftMost = xSorted[:2, :]\n",
        "\trightMost = xSorted[2:, :]\n",
        "\t# now, sort the left-most coordinates according to their\n",
        "\t# y-coordinates so we can grab the top-left and bottom-left\n",
        "\t# points, respectively\n",
        "\tleftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
        "\t(tl, bl) = leftMost\n",
        "\t# now that we have the top-left coordinate, use it as an\n",
        "\t# anchor to calculate the Euclidean distance between the\n",
        "\t# top-left and right-most points; by the Pythagorean\n",
        "\t# theorem, the point with the largest distance will be\n",
        "\t# our bottom-right point\n",
        "\tD = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
        "\t(br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
        "\t# return the coordinates in top-left, top-right,\n",
        "\t# bottom-right, and bottom-left order\n",
        "\treturn np.array([tl, tr, br, bl], dtype=\"int32\")\n",
        "\n",
        "# Calcolo del MRB: https://gis.stackexchange.com/questions/22895/finding-minimum-area-rectangle-for-given-points\n",
        " \n",
        "def minimum_bounding_rectangle(points):\n",
        "    \"\"\"\n",
        "    Find the smallest bounding rectangle for a set of points.\n",
        "    Returns a set of points representing the corners of the bounding box.\n",
        "\n",
        "    :param points: an nx2 matrix of coordinates\n",
        "    :rval: an nx2 matrix of coordinates\n",
        "    \"\"\"\n",
        "    from scipy.ndimage.interpolation import rotate\n",
        "    pi2 = np.pi/2.\n",
        "\n",
        "    # get the convex hull for the points\n",
        "    hull_points = points[ConvexHull(points).vertices]\n",
        "\n",
        "    # calculate edge angles\n",
        "    edges = np.zeros((len(hull_points)-1, 2))\n",
        "    edges = hull_points[1:] - hull_points[:-1]\n",
        "\n",
        "    angles = np.zeros((len(edges)))\n",
        "    angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
        "\n",
        "    angles = np.abs(np.mod(angles, pi2))\n",
        "    angles = np.unique(angles)\n",
        "\n",
        "    # find rotation matrices\n",
        "    # XXX both work\n",
        "    rotations = np.vstack([\n",
        "        np.cos(angles),\n",
        "        np.cos(angles-pi2),\n",
        "        np.cos(angles+pi2),\n",
        "        np.cos(angles)]).T\n",
        "#     rotations = np.vstack([\n",
        "#         np.cos(angles),\n",
        "#         -np.sin(angles),\n",
        "#         np.sin(angles),\n",
        "#         np.cos(angles)]).T\n",
        "    rotations = rotations.reshape((-1, 2, 2))\n",
        "\n",
        "    # apply rotations to the hull\n",
        "    rot_points = np.dot(rotations, hull_points.T)\n",
        "\n",
        "    # find the bounding points\n",
        "    min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
        "    max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
        "    min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
        "    max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
        "\n",
        "    # find the box with the best area\n",
        "    areas = (max_x - min_x) * (max_y - min_y)\n",
        "    best_idx = np.argmin(areas)\n",
        "\n",
        "    # return the best box\n",
        "    x1 = max_x[best_idx]\n",
        "    x2 = min_x[best_idx]\n",
        "    y1 = max_y[best_idx]\n",
        "    y2 = min_y[best_idx]\n",
        "    r = rotations[best_idx]\n",
        "\n",
        "    rval = np.zeros((4, 2))\n",
        "    rval[0] = np.dot([x1, y2], r)\n",
        "    rval[1] = np.dot([x2, y2], r)\n",
        "    rval[2] = np.dot([x2, y1], r)\n",
        "    rval[3] = np.dot([x1, y1], r)\n",
        "\n",
        "    return rval\n",
        "\n",
        "# Da questo post di stackoverflow: https://stackoverflow.com/questions/39308030/how-do-i-increase-the-contrast-of-an-image-in-python-opencv\n",
        "\n",
        "def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n",
        "    \n",
        "    if brightness != 0:\n",
        "        if brightness > 0:\n",
        "            shadow = brightness\n",
        "            highlight = 255\n",
        "        else:\n",
        "            shadow = 0\n",
        "            highlight = 255 + brightness\n",
        "        alpha_b = (highlight - shadow)/255\n",
        "        gamma_b = shadow\n",
        "        \n",
        "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
        "    else:\n",
        "        buf = input_img.copy()\n",
        "    \n",
        "    if contrast != 0:\n",
        "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
        "        alpha_c = f\n",
        "        gamma_c = 127*(1-f)\n",
        "        \n",
        "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
        "\n",
        "    return buf\n",
        "\n",
        "# Funzione per incicciottire il font e renderlo \"continuo\" da puntinato\n",
        "# Vuole in input l'immagine in bianco su nero e non nero su bianco\n",
        "# Restituisce poi un'immagine in bianco e nero\n",
        "\n",
        "def incicciottisci(img, kernelsize=3, shape=cv2.MORPH_ELLIPSE):\n",
        "    kernel = cv2.getStructuringElement(shape,(kernelsize,kernelsize))\n",
        "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
        "    dilation = cv2.dilate(opening,kernel,iterations = 2)\n",
        "    return (255-dilation)\n",
        "\n",
        "# Zoom\n",
        "\n",
        "def clipped_zoom(img, zoom_factor, **kwargs):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        #out = np.zeros_like(img)\n",
        "        # White-padding\n",
        "        out=np.full_like(img,255)\n",
        "\n",
        "        #out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
        "        out[top:top+zh, left:left+zw]=cv2.resize(img, None, fx=zoom_factor, fy=zoom_factor)\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.round(h / zoom_factor))\n",
        "        zw = int(np.round(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[0] - h) // 2)\n",
        "        trim_left = ((out.shape[1] - w) // 2)\n",
        "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    return out\n",
        "\n",
        "# Ruotare l'immagine per raddrizzarla\n",
        "\n",
        "def rotate_image(image, angle, center):\n",
        "  # Questa volta ruoto secondo il punto contro cui calcolo lo skew\n",
        "  image_center = tuple(np.array(center))\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], borderValue=(255,255,255))\n",
        "  return result\n",
        "\n",
        "# Da: https://stackoverflow.com/questions/4993082/how-can-i-sharpen-an-image-in-opencv\n",
        "\n",
        "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n",
        "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
        "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
        "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
        "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
        "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
        "    sharpened = sharpened.round().astype(np.uint8)\n",
        "    if threshold > 0:\n",
        "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
        "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
        "    return sharpened\n",
        "\n",
        "work_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2'\n",
        "#work_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli' # In caso si volessero salvare i ritagli\n",
        "images_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto'\n",
        "CRAFT_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/CRAFT_results'\n",
        "method=3\n",
        "\n",
        "min_area=None\n",
        "max_area=None\n",
        "min_size=None\n",
        "max_size=None\n",
        "min_area_img=None\n",
        "max_area_img=None\n",
        "\n",
        "if not exists(work_folder):\n",
        "  mkdir(work_folder)\n",
        "buoni=join(work_folder,'buoni_{}'.format(method))\n",
        "if not exists(buoni):\n",
        "  mkdir(buoni)\n",
        "buoni_refiner=join(work_folder,'buoni_refiner_{}'.format(method))\n",
        "if not exists(buoni_refiner):\n",
        "  mkdir(buoni_refiner)\n",
        "scarti=join(work_folder,'scarti_{}'.format(method))\n",
        "if not exists(scarti):\n",
        "  mkdir(scarti)\n",
        "scarti_refiner=join(work_folder,'scarti_refiner_{}'.format(method))\n",
        "if not exists(scarti_refiner):\n",
        "  mkdir(scarti_refiner)\n",
        "for folder in ['buoni_results_refiner_{}'.format(method),'scarti_results_refiner_{}'.format(method)]:#,'buoni_results_{}'.format(method),'scarti_results_{}'.format(method)]:\n",
        "  if exists(join(CRAFT_folder,folder)):\n",
        "    files=[f.split('.')[0] for f in listdir(join(CRAFT_folder,folder)) if isfile(join(CRAFT_folder,folder,f)) and (f.split('.')[1]=='txt')]\n",
        "    for file in files:\n",
        "      name=file[4:]\n",
        "      if folder.split('_')[2]=='refiner':\n",
        "        saveto=join(work_folder,folder.split('_')[0]+'_refiner_{}'.format(method),name)\n",
        "      else:\n",
        "        saveto=join(work_folder,folder.split('_')[0]+'_{}'.format(method),name)\n",
        "      if not exists(saveto):\n",
        "        mkdir(saveto)\n",
        "      with open(join(CRAFT_folder,folder,file+'.txt')) as fin:\n",
        "        i=0\n",
        "        for line in fin:\n",
        "          # Ritaglio ogni bounding box e la analizzo singolarmente\n",
        "          # Prendo solo le righe non vuote visto che il test.py di craft stampa una riga vuota dopo ogni riga con delle coordinate\n",
        "          if(len(line)!=1):\n",
        "            coord=np.array(line.rstrip().split(',')).astype(np.int).reshape(-1,2)\n",
        "            if len(coord)>4: # Caso con poligono e non rettangolo/i\n",
        "              print(\"Poligono, estraggo la bounding box rettangolare che lo contiene ({})\".format(saveto))\n",
        "              pts=minimum_bounding_rectangle(coord)\n",
        "              coord=order_points(pts)\n",
        "            # La boundibg box a volte andava fuori dall'immagine e quindi durante il ritaglio si creavano errori...\n",
        "            # Dovrebbe non succedere piu' usando una semplice soluzione quale fare un piccolo zoom (0.9) sull'immagine originale durante il preprocessing (anzi, durante la conversione in jpg in questo caso)\n",
        "            # Calcolo l'angolazione della bounding box negandola in segno per poi sistemare lo skew (potrebbe non essere il metodo migliore se il detector sbaglia l'angolazione della bounding box)\n",
        "            diffs=[coord[0,0]-coord[-1,0],coord[0,1]-coord[-1,1]]\n",
        "            angle=-(math.atan(diffs[0]/diffs[1])*180/math.pi)\n",
        "            # Calcolo la lunghezza dei lati del rettangolo della bounding box\n",
        "            dist1=math.ceil(sqrt((coord[-1,0]-coord[0,0])**2+(coord[-1,1]-coord[0,1])**2))\n",
        "            dist2=math.ceil(sqrt((coord[1,0]-coord[0,0])**2+(coord[1,1]-coord[0,1])**2))\n",
        "            # Ruoto l'immagine rispetto al punto rispetto a cui ho calcolato l'angolo\n",
        "            # Una volta che si ha un formato standard potremmo prendere l'immagine preprocessata e riconoscere direttamente su questa\n",
        "            #print(join(images_folder,folder.split('_')[0]+real_directory_postfix,file.split('_')[1]+'.jpg'))\n",
        "            im=cv2.imread(join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg'),0)\n",
        "            rotated=rotate_image(im,angle,[coord[0,0],coord[0,1]])\n",
        "            # Ritaglio la zona di interesse\n",
        "            cut=rotated[coord[0,1]:coord[0,1]+dist1,coord[0,0]:coord[0,0]+dist2]\n",
        "            # Se in verticale la giro\n",
        "            if cut.shape[0]>cut.shape[1]:\n",
        "              cut=cv2.rotate(cut,0)\n",
        "\n",
        "            # Cerco la dimensione minima e massima delle bounding box\n",
        "            if min_area==None:\n",
        "              min_area=np.prod(cut.shape[:2])\n",
        "              min_size=cut.shape[:2]\n",
        "              min_size_img=join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg')\n",
        "            elif min_area>np.prod(cut.shape[:2]):\n",
        "              min_area=np.prod(cut.shape[:2])\n",
        "              min_size=cut.shape[:2]\n",
        "              min_size_img=join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg')\n",
        "            if max_area==None:\n",
        "              max_area=np.prod(cut.shape[:2])\n",
        "              max_size=cut.shape[:2]\n",
        "              max_size_img=join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg')\n",
        "            elif max_area<np.prod(cut.shape[:2]):\n",
        "              max_area=np.prod(cut.shape[:2])\n",
        "              max_size=cut.shape[:2]\n",
        "              max_size_img=join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg')\n",
        "            #######\n",
        "\n",
        "            if 0==1:  # Per avere i ritagli senza post processing\n",
        "              final=cut\n",
        "            elif 0==0:  # Questi 2 post processing sono praticamente equivalenti, il secondo funziona meglio e soprattutto nei casi con strisce luminose che tagliano le lettere ma e' da affinare un attimo (entrambi fatti da me)\n",
        "              # TODO: Applica il pre-processing prima di fare lo zoom per portare tutto in bianco e nero (dovrebbe essere piu' semplice la questione relativa alle soglie a questo punto)\n",
        "              #######\n",
        "              filtered = cv2.adaptiveThreshold(cut.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 41,3)\n",
        "              bc=apply_brightness_contrast(cut,103,43)\n",
        "              blur_otsu = cv2.GaussianBlur(bc,(7,7),0)\n",
        "              _,thr = cv2.threshold(blur_otsu,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "              or_image = cv2.bitwise_or(thr, filtered)\n",
        "              cic=incicciottisci(255-or_image, 4)  #grande variabilita' con tesseract...4x4 (lo so che sarebbe meglio dispari ma quello che fa al massimo e' traslarmi tutto in diagonale un po' piu' in basso) non riconosce piu' quasi nulla....\n",
        "              blur= cv2.blur(cic,(3,3))\n",
        "              _, thr_post_blur = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "              #######\n",
        "              # Faccio uno zoom di 0.5 per \"aggiungere area\"\n",
        "              final=clipped_zoom(thr_post_blur,0.5)\n",
        "            else:\n",
        "              # TODO: Applica il pre-processing prima di fare lo zoom per portare tutto in bianco e nero (dovrebbe essere piu' semplice la questione relativa alle soglie a questo punto)\n",
        "              #######\n",
        "              filtered = cv2.adaptiveThreshold(cut.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 41,3)\n",
        "              bc=apply_brightness_contrast(cut,97,67)\n",
        "              blur_otsu = cv2.GaussianBlur(bc,(9,9),0)\n",
        "              thr=cv2.adaptiveThreshold(blur_otsu,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,41,5)\n",
        "              or_image = cv2.bitwise_or(thr, filtered)\n",
        "              cic=incicciottisci(255-or_image, 4)  #grande variabilita' con tesseract...4x4 (lo so che sarebbe meglio dispari ma quello che fa al massimo e' traslarmi tutto in diagonale un po' piu' in basso) non riconosce piu' quasi nulla....\n",
        "              blur= cv2.blur(cic,(3,3))\n",
        "              _, thr_post_blur = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "              #######\n",
        "              # Faccio uno zoom di 0.5 per \"aggiungere area\"\n",
        "              final=clipped_zoom(thr_post_blur,0.5)\n",
        "            final_flipped=cv2.rotate(final,1)\n",
        "            # Salvo\n",
        "            im_pil = Image.fromarray(final)\n",
        "            im_pil.save(join(saveto,'{}'.format(i)+'.jpg'), dpi=(300.0, 300.0))\n",
        "            im_pil = Image.fromarray(final_flipped)\n",
        "            im_pil.save(join(saveto,'{}'.format(i)+'_flipped.jpg'), dpi=(300.0, 300.0))\n",
        "            #cv2.imwrite(join(saveto,'{}'.format(i)+'.jpg'),final)\n",
        "            #cv2.imwrite(join(saveto,'{}'.format(i)+'_flipped.jpg'),final_flipped)\n",
        "            i+=1\n",
        "        if i==0:\n",
        "          print(\"Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine \"+join(images_folder,folder.split('_')[0]+'_jpg',name+'.jpg'))\n",
        "  else:\n",
        "    print(folder+' non esiste! Eseguire prima la fase di detection...')\n",
        "print('min_size: ',min_size)\n",
        "print('min_area: ',min_area)\n",
        "print('min_size_img: ',min_size_img)\n",
        "print('max_size: ',max_size)\n",
        "print('max_area: ',max_area)\n",
        "print('max_size_img: ',max_size_img)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img10)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img14)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img18)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img17)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img11)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img32)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img24)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img19)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img39)\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img42_lowExp)\n",
            "Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img40.jpg\n",
            "Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img36.jpg\n",
            "Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img41.jpg\n",
            "Poligono, estraggo la bounding box rettangolare che lo contiene (/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/ritagli/scarti_refiner_3/Img38)\n",
            "Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img47.jpg\n",
            "Non e' stata rilevata la presenza di alcun testo (nessuna bounding box) nell'immagine /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img48.jpg\n",
            "min_size:  (93, 96)\n",
            "min_area:  8928\n",
            "min_size_img:  /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/buoni_jpg/Img8.jpg\n",
            "max_size:  (329, 1424)\n",
            "max_area:  468496\n",
            "max_size_img:  /content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/scarti_jpg/Img24.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L2ZxgmxGfPi"
      },
      "source": [
        "### Riconoscimento (da fare su windows o comunque non su colab)\n",
        "Provare ad utilizzare il modello trainato di tesseract per i display a matrice di punti trovato su github per vedere se performa meglio dell'iniciccionimento dei punti per cercare di far diventare il font puntinato continuo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4jRSb1IG3fB",
        "outputId": "e18c2466-1eae-4578-e92f-3128fc898578"
      },
      "source": [
        "# Immagini labellate con il testo che dovremmo riconoscere (basta fare una ricerca sul se la stringa trovata con tesseract e' contenuta nella stringa di ogni chiave del dizionario dell immagini)\n",
        "# Provare poi sostituendo i caratteri ambigui come \"O\" e \"0\"; penso siano gli unici in quanto sostiuire i le \"T\" con i \"7\" non sarebbe corretto o i \"5\" con le \"S\" (e viceversa tutti i casi)\n",
        "labels={'Img0': ['LOTTO:L20L0M\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img1': ['LOTTO:L20L0M\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img2': ['L20K77\\n11-2022'],\n",
        "\t\t\t\t'Img3': ['L20K77\\n11-2022'],\n",
        "\t\t\t\t'Img4': ['LOTTO:L20K6X\\nSCAD.:11-2023'],\n",
        "\t\t\t\t'Img5': ['LOTTO:L20K6X\\nSCAD.:11-2023'],\n",
        "\t\t\t\t'Img6': ['LOTTO:L20K6X\\nSCAD.:11-2023'],\n",
        "\t\t\t\t'Img7': ['LOTTO:L20K6X\\nSCAD.:11-2023'],\n",
        "\t\t\t\t'Img8': ['L20L09\\n12-2022'],\n",
        "\t\t\t\t'Img9': ['L20L09\\n12-2022'],\n",
        "        'Img10': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img11': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img12': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img13': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img14': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img15': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img16': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img17': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img18': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img19': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img20': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img21': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img22': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img23': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img24': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img25': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img26': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img27': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img28': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img29': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img30': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img31': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img32': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img33': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img34': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img35': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img36': [''],\n",
        "\t\t\t\t'Img37': [''],\n",
        "\t\t\t\t'Img38': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img39': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img40': [''],\n",
        "\t\t\t\t'Img40_lowExp': [''],\n",
        "\t\t\t\t'Img41': [''],\n",
        "\t\t\t\t'Img42': [''],\n",
        "\t\t\t\t'Img42_lowExp': [''],\n",
        "\t\t\t\t'Img43': [''],\n",
        "\t\t\t\t'Img44': [''],\n",
        "\t\t\t\t'Img45': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img46': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img47': [''],\n",
        "\t\t\t\t'Img48': [''],\n",
        "\t\t\t\t'Img49': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img50': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img51': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "\t\t\t\t'Img52': ['LOTTO:L20L0L\\nSCAD.:12-2022'],\n",
        "        }\n",
        "\n",
        "import pytesseract\n",
        "from os.path import exists, join, isfile, isdir\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "import os\n",
        "\n",
        "traineddata_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi'\n",
        "tessdata_folder='/usr/share/tesseract-ocr/4.00/tessdata'\n",
        "os.putenv(\"TESSDATA_PREFIX\", tessdata_folder)\n",
        "if not exists(join(traineddata_folder,'LCDDot_FT_500.traineddata')):\n",
        "  !wget https://github.com/ameera3/OCR_Expiration_Date/blob/master/OCR_Ensemble/LCDDot_FT_500.traineddata -P \"$traineddata_folder\"\n",
        "if not exists(join(traineddata_folder,'dotslayer.traineddata')):\n",
        "  !wget https://github.com/Shreeshrii/tessdata_shreetest/blob/master/dotslayer.traineddata -P \"$traineddata_folder\"\n",
        "# Trovare per quale motivo funziona installare la lingua italiana per tesseract mentre non funziona, neanche con l'italiano scaricato dalla pagina github ufficiale dei file di tesseract trainati, portarli nella cartella. Probabile ci sia un comando per fare il refresh di tesseract\n",
        "if not exists(join(traineddata_folder,'ita.traineddata')):\n",
        "  !wget https://github.com/tesseract-ocr/tessdata/blob/master/ita.traineddata -P \"$traineddata_folder\"\n",
        "\n",
        "#copyfile(join(traineddata_folder,'LCDDot_FT_500.traineddata'), join(tessdata_folder,'LCDDot_FT_500.traineddata'))\n",
        "#copyfile(join(traineddata_folder,'dotslayer.traineddata'), join(tessdata_folder,'dotslayer.traineddata'))\n",
        "#copyfile(join(traineddata_folder,'ita.traineddata'), join(tessdata_folder,'ita.traineddata'))\n",
        "\n",
        "# Sintassi generale per usare il comando con le opzioni di configurazione per tesseract\n",
        "#target = pytesseract.image_to_string(image, lang='eng', boxes=False, config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789')\n",
        "# Da prelevare l'immagine giusta o la cartella con le immagini di tutte le boundibg box ritagliate\n",
        "if 0==1: # Da fare al pc, qui da solo errori usando altri file trainati\n",
        "  detected_folder='/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2'\n",
        "  folders=[d for d in listdir(detected_folder) if isdir(join(detected_folder,d))]\n",
        "  for folder in ['buoni_refiner_3','scarti_refiner_3']: #folders:\n",
        "    images=[d for d in listdir(join(detected_folder,folder)) if isdir(join(detected_folder,folder,d))]\n",
        "    images.sort()\n",
        "    for image in images:\n",
        "      files=[f for f in listdir(join(detected_folder,folder,image)) if isfile(join(detected_folder,folder,image,f))]\n",
        "      LCDDot_FT_500=[]\n",
        "      dotslayer=[]\n",
        "      ita=[]\n",
        "      eng=[]\n",
        "      for file in files:\n",
        "        # In caso si utilizzi il metodo 2: psm=8 per indicare a tesseract che dovra' rilevare una singola parola, oem=3 di default e nessuna whitelist per ora\n",
        "        # Senza usare il file trainato per il font a matrice di punti\n",
        "        # Ha bisogno dell'utilizzo della funzione link dots per ingrassare i punti e cercare di rendere il font normale\n",
        "        img=join(detected_folder,folder,image,file)\n",
        "        print(img+'({})'.format(labels[file]))\n",
        "        # Suppongo si possano togliere caratteri tipo la O o lo 0, la I o L'1, la A con il 4, Z con 2\n",
        "        # (per evitare casi ambigui suppongo si possano stampare solo determinate combinazioni con meno caratteri, come nelle targhe... Poi si puo' modificare in ogni caso)\n",
        "        LCDDot_FT_500.append(pytesseract.image_to_string(img, lang='LCDDot_FT_500', config=\"-c tessedit_char_whitelist=123456789ABCDEFGHJKLMNOPQRSTUVWXY.-:\").replace('\\n','#').replace(' ',''))\n",
        "        dotslayer.append(pytesseract.image_to_string(img, lang='dotslayer', config=\"-c tessedit_char_whitelist=123456789ABCDEFGHJKLMNOPQRSTUVWXY.-:\").replace('\\n','#').replace(' ',''))\n",
        "        ita.append(pytesseract.image_to_string(img, lang='ita', config=\"-c tessedit_char_whitelist=123456789BCDEFGHJKLMNOPQRSTUVWXY.-:\").replace('\\n','#').replace(' ',''))\n",
        "        eng.append(pytesseract.image_to_string(img, lang='eng', config=\"-c tessedit_char_whitelist=123456789BCDEFGHJKLMNOPQRSTUVWXY.-:\").replace('\\n','#').replace(' ',''))\n",
        "        print(\"\\tTesseract result (LCDDot_FT_500.traineddata):\",LCDDot_FT_500)\n",
        "        print(\"\\tTesseract result (dotslayer.traineddata):\",dotslayer)\n",
        "        print(\"\\tTesseract result (ita.traineddata):\",ita)\n",
        "        print(\"\\tTesseract result (eng.traineddata):\",eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/0.jpg\n",
            "LIOTTTICLI###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/0_flipped.jpg\n",
            "\"TRILLO###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/1.jpg\n",
            "i ZOLCOH###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/1_flipped.jpg\n",
            "UNO###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/3.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/3_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/4.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img0/4_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/0.jpg\n",
            "L20801###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/0_flipped.jpg\n",
            "AD###TE]###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/1.jpg\n",
            "LUTTO?###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/1_flipped.jpg\n",
            "#5 4£L0 0###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/2.jpg\n",
            "vil###vii###Dl######DI######C.]###veni###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/2_flipped.jpg\n",
            "Boe###ia######Pu###(3###Li###Mu###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/3.jpg\n",
            "LO###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img1/3_flipped.jpg\n",
            "UO###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/0.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/0_flipped.jpg\n",
            "i######Pr######-_ ———###. Grì###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/1.jpg\n",
            "[x]###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/1_flipped.jpg\n",
            "[x###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/3.jpg\n",
            "SL MO######Co######7###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img2/3_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/0.jpg\n",
            " ###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/0_flipped.jpg\n",
            " ###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/1.jpg\n",
            "Lav,###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/1_flipped.jpg\n",
            "ur###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/3.jpg\n",
            "SZO0%-II###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/3_flipped.jpg\n",
            "i1-202®###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/4.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/4_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/5.jpg\n",
            " ###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img3/5_flipped.jpg\n",
            " ###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/0.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/0_flipped.jpg\n",
            "SCAD, *###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/1.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/1_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img4/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/0.jpg\n",
            "» HIS###sOLLO###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/0_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/1.jpg\n",
            "EZ07-11###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/1_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/3.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img5/3_flipped.jpg\n",
            "cr###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/0.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/0_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/1.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/1_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/2.jpg\n",
            "intel###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img6/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/0.jpg\n",
            "» GHIS###\"01107###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/0_flipped.jpg\n",
            "SCAD, ©###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/1.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/1_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/2.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img7/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/0.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/0_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/1.jpg\n",
            "ZZ20Ze-Z1###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/1_flipped.jpg\n",
            "i 2-2022###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/2.jpg\n",
            "(KE###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/2_flipped.jpg\n",
            "[etc]###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/3.jpg\n",
            "SOTTO \"1###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img8/3_flipped.jpg\n",
            "LEOL.O09###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/0.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/0_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/1.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/1_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/2.jpg\n",
            "[Lei###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/2_flipped.jpg\n",
            "\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/3.jpg\n",
            "SO0TtOoz\"I###\f\n",
            "/content/drive/Shareddrives/Tesi Martignetti-Papallazi/Pictures SALF/Verifica Lotto/metodo_2/buoni_3/Img9/3_flipped.jpg\n",
            "\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8hk8JrU5v-_"
      },
      "source": [
        "# Analisi dei risultati\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drY5HXd_50nw"
      },
      "source": [
        "## Con le liste\n",
        "<b>TODO</b>: integrare la lettura di tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ika1Tugd56Uy",
        "outputId": "a2d6e588-d81b-4d9e-c81f-65e6924dc2b7"
      },
      "source": [
        "# correct content of the images\n",
        "labels = [[0, 'Img0.jpg', 'L20L0M', '12-2022'],\n",
        "          [0, 'Img0_flipped.jpg', 'L20L0M', '12-2022'],\n",
        "          [0, 'Img1.jpg', 'L20L0M', '12-2022'],\n",
        "          [0, 'Img1_flipped.jpg', 'L20L0M', '12-2022'],\n",
        "          [1, 'Img2.jpg', 'L20K77', '11-2022'],\n",
        "          [1, 'Img2_flipped.jpg', 'L20K77', '11-2022'],\n",
        "          [1, 'Img3.jpg', 'L20K77', '11-2022'],\n",
        "          [1, 'Img3_flipped.jpg', 'L20K77', '11-2022'],\n",
        "          [2, 'Img4.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img4_flipped.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img5.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img5_flipped.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img6.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img6_flipped.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img7.jpg', 'L20K6X', '11-2023'],\n",
        "          [2, 'Img7_flipped.jpg', 'L20K6X', '11-2023'],\n",
        "          [3, 'Img8.jpg', 'L20L09', '12-2022'],\n",
        "          [3, 'Img8_flipped.jpg', 'L20L09', '12-2022'],\n",
        "          [3, 'Img9.jpg', 'L20L09', '12-2022'],\n",
        "          [3, 'Img9_flipped.jpg', 'L20L09', '12-2022'],]\n",
        "# reading of tesseract\n",
        "tesseract_read = range(len(labels))\n",
        "# \n",
        "right = 0\n",
        "wrong = 0\n",
        "for i in tesseract_read:\n",
        "  if tesseract_read[i] == labels[i]:\n",
        "    right = right + 1\n",
        "  else: wrong = wrong + 1\n",
        "\n",
        "print('right: ' + str(right))\n",
        "print('wrong: ' + str(wrong))\n",
        "print(str(right/wrong*100) + '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "right: 0\n",
            "wrong: 20\n",
            "0.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}